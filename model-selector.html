<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Select AI Model</title>
  <link rel="stylesheet" href="styles.css">
</head>

<body>
  <h1>Select AI Model</h1>

  <div class="section">
    <h2>AI Provider</h2>
    <div class="radio-group">
      <label>
        <input type="radio" name="aiProvider" value="openai" checked> OpenAI (Requires API Key)
      </label>
      <label>
        <input type="radio" name="aiProvider" value="ollama"> Ollama (Local, free)
      </label>
      <label>
        <input type="radio" name="aiProvider" value="gemini"> Gemini (Google AI, Requires API Key)
      </label>
    </div>
  </div>

  <div class="section" id="openai-section">
    <h2>OpenAI Models</h2>
    <select id="openai-model">
      <option value="gpt-4o-mini">gpt-4o-mini</option>
      <option value="gpt-4o">gpt-4o</option>
      <option value="gpt-4-vision-preview">gpt-4-vision-preview</option>
      <option value="gpt-4-turbo">gpt-4-turbo</option>
    </select>
  </div>

  <div class="section" id="gemini-section" style="display: none;">
    <h2>Gemini Models</h2>
    <div id="gemini-loading" class="flex justify-between items-center">
      <span>Loading Gemini models... <span class="loading"></span></span>
    </div>
    <select id="gemini-model" class="mt-2">
      <option value="loading">Loading models...</option>
    </select>
    <div class="text-xs opacity-50 mt-2">Note: All Gemini models have excellent vision and streaming capabilities.</div>
  </div>

  <div class="section" id="ollama-section" style="display: none;">
    <h2>Ollama Models</h2>
    <div class="flex justify-between items-center">
      <span id="ollama-status">Checking for Ollama models...</span>
      <button id="refresh-models" class="btn-primary">Refresh Models</button>
    </div>
    <select id="ollama-model" class="mt-2">
      <option value="loading">Loading...</option>
    </select>

    <div id="vision-models-note" class="text-xs opacity-50 mt-2 mb-2" style="display: none;">
      Note: For image processing, it's recommended to use multi-modal models like:
      llava, bakllava, deepseek-r1, or moondream
    </div>

    <h3>Ollama URL</h3>
    <input type="text" id="ollama-url" placeholder="http://127.0.0.1:11434" value="http://127.0.0.1:11434">
    <div class="text-xs opacity-50">Note: Use 127.0.0.1 instead of localhost to avoid IPv6 connection issues</div>

    <div id="connection-test-result" class="status"></div>
    <div class="flex justify-between mt-4">
      <button id="test-connection" class="btn-primary">Test Connection</button>
      <button id="pull-model-btn" class="btn-warning">Pull Model</button>
    </div>
  </div>

  <div class="flex justify-between mt-4">
    <button id="save-settings" class="btn-success">Save Settings</button>
    <button id="cancel" class="btn">Cancel</button>
  </div>

  <div id="message" class="status"></div>

  <!-- Pull model modal dialog -->
  <div id="pull-model-modal" class="modal">
    <div class="modal-content">
      <span class="close-modal">&times;</span>
      <h3>Pull Ollama Model</h3>
      <p>Enter the name of the model to pull:</p>
      <input type="text" id="model-to-pull" placeholder="e.g., llava:latest" class="w-full mt-2 mb-2">
      <div class="text-xs opacity-50">Recommended multimodal models: llava, bakllava, deepseek-r1, moondream</div>
      <div id="pull-status" class="status"></div>
      <div class="flex justify-between mt-4">
        <button id="confirm-pull" class="btn-success">Pull Model</button>
        <button id="cancel-pull" class="btn">Cancel</button>
      </div>
    </div>
  </div>

  <script>
    const { ipcRenderer } = require('electron');
    const axios = require('axios');
    const fs = require('fs');
    const path = require('path');

    // Elements
    const aiProviderRadios = document.querySelectorAll('input[name="aiProvider"]');
    const openaiSection = document.getElementById('openai-section');
    const ollamaSection = document.getElementById('ollama-section');
    const geminiSection = document.getElementById('gemini-section');
    const geminiLoading = document.getElementById('gemini-loading');
    const openaiModelSelect = document.getElementById('openai-model');
    const ollamaModelSelect = document.getElementById('ollama-model');
    const geminiModelSelect = document.getElementById('gemini-model');
    const ollamaUrlInput = document.getElementById('ollama-url');
    const ollamaStatus = document.getElementById('ollama-status');
    const visionModelsNote = document.getElementById('vision-models-note');
    const refreshModelsBtn = document.getElementById('refresh-models');
    const testConnectionBtn = document.getElementById('test-connection');
    const pullModelBtn = document.getElementById('pull-model-btn');
    const connectionTestResult = document.getElementById('connection-test-result');
    const saveBtn = document.getElementById('save-settings');
    const cancelBtn = document.getElementById('cancel');
    const messageDiv = document.getElementById('message');

    // Pull model modal elements
    const pullModelModal = document.getElementById('pull-model-modal');
    const closeModalBtn = document.querySelector('.close-modal');
    const modelToPullInput = document.getElementById('model-to-pull');
    const pullStatusDiv = document.getElementById('pull-status');
    const confirmPullBtn = document.getElementById('confirm-pull');
    const cancelPullBtn = document.getElementById('cancel-pull');

    // Load current settings
    let currentSettings = {};
    let geminiApiKey = ''; // Will store the API key from .env

    // Detect platform for correct key labels
    const isMac = navigator.platform.includes('Mac');
    const modifierKey = isMac ? 'Command' : 'Ctrl';

    // Function to parse the .env file and get the GEMINI_API_KEY
    function getGeminiApiKey() {
      try {
        // Read the .env file from the application root directory
        const envPath = path.join(process.cwd(), '.env');
        if (fs.existsSync(envPath)) {
          const envContent = fs.readFileSync(envPath, 'utf8');
          const lines = envContent.split('\n');

          for (const line of lines) {
            if (line.startsWith('GEMINI_API_KEY=')) {
              return line.substring('GEMINI_API_KEY='.length).trim();
            }
          }
        }

        // If we couldn't find the key in .env, check environment variables
        if (process.env.GEMINI_API_KEY) {
          return process.env.GEMINI_API_KEY;
        }

        return ''; // Return empty string if no key found
      } catch (error) {
        console.error('Error reading .env file:', error);
        return '';
      }
    }

    // Function to fetch Gemini models from the API
    async function fetchGeminiModels() {
      geminiLoading.innerHTML = 'Loading Gemini models... <span class="loading"></span>';
      geminiModelSelect.innerHTML = '<option value="loading">Loading models...</option>';

      try {
        // Get API key from .env file
        geminiApiKey = getGeminiApiKey();

        if (!geminiApiKey) {
          geminiLoading.textContent = 'Error: No Gemini API key found in .env file';
          geminiModelSelect.innerHTML = '<option value="">No API key available</option>';
          return;
        }

        // Make API request to get available models
        const response = await axios.get(`https://generativelanguage.googleapis.com/v1beta/models?key=${geminiApiKey}`);

        if (response.data && response.data.models) {
          // Clear the select element
          geminiModelSelect.innerHTML = '';

          // Filter for Gemini models
          const geminiModels = response.data.models.filter(model =>
            model.name.includes('gemini') &&
            !model.name.includes('embedding') &&
            model.supportedGenerationMethods.includes('generateContent')
          );

          if (geminiModels.length === 0) {
            geminiLoading.textContent = 'No Gemini models found';
            geminiModelSelect.innerHTML = '<option value="">No models available</option>';
            return;
          }

          // Sort by display name
          geminiModels.sort((a, b) => {
            // Put Flash models first, then Pro models, then others
            const aName = a.displayName.toLowerCase();
            const bName = b.displayName.toLowerCase();

            if (aName.includes('flash') && !bName.includes('flash')) return -1;
            if (!aName.includes('flash') && bName.includes('flash')) return 1;
            if (aName.includes('pro') && !bName.includes('pro')) return 1;
            if (!aName.includes('pro') && bName.includes('pro')) return -1;

            return aName.localeCompare(bName);
          });

          // Add models to select
          geminiModels.forEach(model => {
            const option = document.createElement('option');
            const modelId = model.name.replace('models/', '');
            option.value = modelId;

            // Create a display name with additional info
            let displayName = model.displayName;

            // Add token info if available
            if (model.inputTokenLimit) {
              // Format large numbers with K or M for readability
              let tokenLimit = model.inputTokenLimit;
              if (tokenLimit >= 1000000) {
                tokenLimit = (tokenLimit / 1000000).toFixed(1) + 'M';
              } else if (tokenLimit >= 1000) {
                tokenLimit = (tokenLimit / 1000).toFixed(0) + 'K';
              }

              displayName += ` (${tokenLimit} tokens)`;
            }

            option.textContent = displayName;

            // Add data attributes for more info
            if (model.description) {
              option.setAttribute('title', model.description);
            }

            geminiModelSelect.appendChild(option);
          });

          // Update the loading message
          geminiLoading.textContent = `${geminiModels.length} Gemini models available`;

          // Select the current model if it exists
          if (currentSettings.aiProvider === 'gemini' && currentSettings.currentModel) {
            const option = Array.from(geminiModelSelect.options).find(opt =>
              opt.value === currentSettings.currentModel ||
              currentSettings.currentModel.includes(opt.value)
            );

            if (option) {
              geminiModelSelect.value = option.value;
            } else {
              // Select a default model - prefer gemini-1.5-flash if available
              const defaultOption = Array.from(geminiModelSelect.options).find(opt =>
                opt.value.includes('gemini-1.5-flash') ||
                opt.value.includes('gemini-pro')
              );

              if (defaultOption) {
                geminiModelSelect.value = defaultOption.value;
              }
            }
          }
        } else {
          geminiLoading.textContent = 'Error: Invalid response from Gemini API';
          geminiModelSelect.innerHTML = '<option value="">Error loading models</option>';
        }
      } catch (error) {
        console.error('Error fetching Gemini models:', error);
        geminiLoading.textContent = `Error: ${error.message}`;
        geminiModelSelect.innerHTML = '<option value="">Error loading models</option>';
      }
    }

    // Test Ollama connection
    async function testOllamaConnection() {
      connectionTestResult.innerHTML = 'Testing connection... <span class="loading"></span>';
      connectionTestResult.className = 'status';

      try {
        // Always use IPv4 by replacing localhost with 127.0.0.1
        const url = ollamaUrlInput.value.replace('localhost', '127.0.0.1');

        const response = await axios.get(`${url}/api/version`, {
          timeout: 5000,
          validateStatus: false
        });

        if (response.status === 200) {
          connectionTestResult.textContent = `Connected successfully! Ollama version: ${response.data.version}`;
          connectionTestResult.className = 'status success';
          return true;
        } else {
          connectionTestResult.textContent = `Error: Received status ${response.status}`;
          connectionTestResult.className = 'status error';
          return false;
        }
      } catch (error) {
        connectionTestResult.textContent = `Connection failed: ${error.message}`;
        connectionTestResult.className = 'status error';
        return false;
      }
    }

    async function loadCurrentSettings() {
      try {
        currentSettings = await ipcRenderer.invoke('get-current-settings');
      } catch (error) {
        console.error("Error getting current settings:", error.message);
        // Set default settings if handler is not registered
        currentSettings = {
          aiProvider: 'openai',
          currentModel: 'gpt-4o-mini',
          ollamaUrl: 'http://127.0.0.1:11434'
        };

        // Show notification about missing handler
        messageDiv.textContent = 'Settings system not fully initialized. Using default configuration.';
        messageDiv.className = 'status warning';
      }

      // Set UI based on current settings
      document.querySelector(`input[name="aiProvider"][value="${currentSettings.aiProvider}"]`).checked = true;

      // Replace localhost with 127.0.0.1 for better compatibility
      const baseUrl = currentSettings.ollamaUrl || 'http://127.0.0.1:11434';
      ollamaUrlInput.value = baseUrl.replace('localhost', '127.0.0.1');

      // Select the appropriate model in dropdown
      if (currentSettings.aiProvider === 'openai') {
        // Try to find the model in the dropdown, default to first option if not found
        const option = Array.from(openaiModelSelect.options).find(opt => opt.value === currentSettings.currentModel);
        if (option) {
          openaiModelSelect.value = currentSettings.currentModel;
        }
      } else if (currentSettings.aiProvider === 'gemini') {
        fetchGeminiModels();
      }

      // Update visibility based on provider
      updateSectionVisibility(currentSettings.aiProvider);

      // Load Ollama models
      if (currentSettings.aiProvider === 'ollama') {
        loadOllamaModels();
      }
    }

    // Update section visibility based on selected provider
    function updateSectionVisibility(provider) {
      if (provider === 'openai') {
        openaiSection.style.display = 'block';
        ollamaSection.style.display = 'none';
        geminiSection.style.display = 'none';
      } else if (provider === 'gemini') {
        openaiSection.style.display = 'none';
        ollamaSection.style.display = 'none';
        geminiSection.style.display = 'block';
      } else {
        openaiSection.style.display = 'none';
        ollamaSection.style.display = 'block';
        geminiSection.style.display = 'none';
      }

      // If switching to Gemini, fetch models
      if (provider === 'gemini') {
        fetchGeminiModels();
      }
    }

    // Load models from Ollama
    async function loadOllamaModels() {
      ollamaStatus.innerHTML = 'Loading models... <span class="loading"></span>';
      ollamaStatus.className = 'status';
      visionModelsNote.style.display = 'none';

      try {
        let models = [];
        try {
          models = await ipcRenderer.invoke('get-ollama-models');
        } catch (invokeError) {
          // Handle missing handler or other errors
          if (invokeError.message.includes('No handler registered for')) {
            ollamaStatus.textContent = 'Ollama support is not fully configured. Other AI providers are still available.';
            ollamaStatus.className = 'status error';
            ollamaModelSelect.innerHTML = '<option value="">Ollama not configured</option>';
            return;
          } else {
            throw invokeError; // Re-throw other errors to be caught below
          }
        }

        // Clear and populate the select
        ollamaModelSelect.innerHTML = '';

        if (models.length === 0) {
          ollamaModelSelect.innerHTML = '<option value="">No models found</option>';
          ollamaStatus.textContent = 'No models found. Is Ollama running?';
          ollamaStatus.className = 'status error';
          return;
        }

        // Check for vision models
        let hasVisionModels = false;
        const visionModelNames = ['llava', 'bakllava', 'moondream', 'deepseek'];

        // Add all models to dropdown
        models.forEach(model => {
          const option = document.createElement('option');
          option.value = model.name;
          option.textContent = model.name;

          // Check if this is a vision model
          const isVisionModel = visionModelNames.some(name => model.name.toLowerCase().includes(name));
          if (isVisionModel) {
            hasVisionModels = true;
            option.textContent += ' (Vision)';
            option.setAttribute('data-is-vision', 'true');
          }

          ollamaModelSelect.appendChild(option);
        });

        // If the current model is set and exists in the list, select it
        if (currentSettings.aiProvider === 'ollama' && currentSettings.currentModel) {
          const option = Array.from(ollamaModelSelect.options).find(opt => opt.value === currentSettings.currentModel);
          if (option) {
            ollamaModelSelect.value = currentSettings.currentModel;
          }
        }

        // Show vision model note if needed
        if (hasVisionModels) {
          visionModelsNote.style.display = 'block';
        }

        ollamaStatus.textContent = `${models.length} models loaded`;
        ollamaStatus.className = 'status success';
      } catch (error) {
        ollamaStatus.textContent = `Error: ${error.message}`;
        ollamaStatus.className = 'status error';
        ollamaModelSelect.innerHTML = '<option value="">Error loading models</option>';

        // Check if the error is likely due to Ollama not running
        if (error.message.includes('ECONNREFUSED') || error.message.includes('ECONNRESET')) {
          ollamaStatus.textContent = 'Cannot connect to Ollama. Is Ollama running?';
        }
      }
    }

    // Pull an Ollama model
    async function pullOllamaModel(modelName) {
      pullStatusDiv.innerHTML = `Pulling model ${modelName}... <span class="loading"></span>`;
      pullStatusDiv.className = 'status';
      confirmPullBtn.disabled = true;

      try {
        // Always use IPv4 by replacing localhost with 127.0.0.1
        const url = ollamaUrlInput.value.replace('localhost', '127.0.0.1');

        pullStatusDiv.textContent = `Sending pull request for ${modelName}...`;

        // Use Ollama API to pull the model
        const response = await axios.post(`${url}/api/pull`, {
          name: modelName,
          stream: false
        }, {
          timeout: 300000 // 5 minute timeout for pulling
        });

        if (response.data && response.data.status === 'success') {
          pullStatusDiv.textContent = `Successfully pulled model: ${modelName}`;
          pullStatusDiv.className = 'status success';

          // Reload the model list
          await loadOllamaModels();

          // Select the newly pulled model
          const option = Array.from(ollamaModelSelect.options).find(opt => opt.value === modelName);
          if (option) {
            ollamaModelSelect.value = modelName;
          }

          // Close the modal after a delay
          setTimeout(() => {
            pullModelModal.style.display = 'none';
            confirmPullBtn.disabled = false;
          }, 2000);

          return true;
        } else {
          pullStatusDiv.textContent = `Error pulling model: ${response.data.status || 'Unknown error'}`;
          pullStatusDiv.className = 'status error';
          confirmPullBtn.disabled = false;
          return false;
        }
      } catch (error) {
        pullStatusDiv.textContent = `Error pulling model: ${error.message}`;
        pullStatusDiv.className = 'status error';
        confirmPullBtn.disabled = false;
        return false;
      }
    }

    // Event Listeners
    for (const radio of aiProviderRadios) {
      radio.addEventListener('change', () => {
        const provider = radio.value;
        updateSectionVisibility(provider);

        // Load models based on provider
        if (provider === 'ollama') {
          loadOllamaModels();
        } else if (provider === 'gemini') {
          fetchGeminiModels();
        }
      });
    }

    refreshModelsBtn.addEventListener('click', loadOllamaModels);
    testConnectionBtn.addEventListener('click', testOllamaConnection);

    // Pull model button
    pullModelBtn.addEventListener('click', () => {
      // Suggest a vision model
      modelToPullInput.value = 'llava:latest';
      pullStatusDiv.textContent = '';
      pullStatusDiv.className = 'status';
      confirmPullBtn.disabled = false;
      pullModelModal.style.display = 'block';
    });

    // Modal close button
    closeModalBtn.addEventListener('click', () => {
      pullModelModal.style.display = 'none';
    });

    // Cancel pull button
    cancelPullBtn.addEventListener('click', () => {
      pullModelModal.style.display = 'none';
    });

    // Confirm pull button
    confirmPullBtn.addEventListener('click', async () => {
      const modelName = modelToPullInput.value.trim();
      if (!modelName) {
        pullStatusDiv.textContent = 'Please enter a model name';
        pullStatusDiv.className = 'status error';
        return;
      }

      await pullOllamaModel(modelName);
    });

    // Close modal if clicking outside
    window.addEventListener('click', (event) => {
      if (event.target === pullModelModal) {
        pullModelModal.style.display = 'none';
      }
    });

    // Save button handler
    saveBtn.addEventListener('click', async () => {
      const aiProvider = document.querySelector('input[name="aiProvider"]:checked').value;
      let currentModel;

      if (aiProvider === 'openai') {
        currentModel = openaiModelSelect.value;
      } else if (aiProvider === 'gemini') {
        currentModel = geminiModelSelect.value;
      } else {
        currentModel = ollamaModelSelect.value;
      }

      // Validate selection
      if (aiProvider === 'ollama' && (!currentModel || currentModel === 'loading' || currentModel === 'Ollama not configured')) {
        messageDiv.textContent = 'Please select a valid Ollama model';
        messageDiv.className = 'status error';
        return;
      }

      // For Ollama, always ensure we're using IPv4
      let ollamaUrl = ollamaUrlInput.value;
      if (aiProvider === 'ollama') {
        ollamaUrl = ollamaUrl.replace('localhost', '127.0.0.1');

        // If using Ollama, test the connection first
        messageDiv.innerHTML = 'Testing Ollama connection... <span class="loading"></span>';
        messageDiv.className = 'status';

        try {
          const connectionTest = await axios.get(`${ollamaUrl}/api/version`, {
            timeout: 3000,
            validateStatus: false
          });

          if (connectionTest.status !== 200) {
            messageDiv.textContent = `Could not connect to Ollama at ${ollamaUrl}. Check if Ollama is running.`;
            messageDiv.className = 'status error';
            return;
          }

          // Connection successful, continue with saving
        } catch (error) {
          messageDiv.textContent = `Connection to Ollama failed: ${error.message}`;
          messageDiv.className = 'status error';
          return;
        }
      }

      // Disable the save button to prevent multiple clicks
      saveBtn.disabled = true;

      // Create settings object to save
      const settings = {
        aiProvider,
        currentModel,
        ollamaUrl
      };

      try {
        // Update settings
        ipcRenderer.send('update-model-settings', settings);

        // Show success message
        messageDiv.textContent = 'Settings saved!';
        messageDiv.className = 'status success';

        // Try to save settings to localStorage as fallback
        try {
          localStorage.setItem('model-settings', JSON.stringify(settings));
        } catch (storageErr) {
          console.error('Could not save to localStorage:', storageErr);
        }

        // For better synchronization, force the main window to refresh model badge
        try {
          // Check if we were opened by a parent window
          if (window.opener) {
            window.opener.postMessage({ type: 'model-settings-updated', settings }, '*');
          }
        } catch (e) {
          console.error('Error notifying parent window:', e);
        }

        // Close window after a brief delay
        setTimeout(() => {
          window.close();
        }, 800);
      } catch (error) {
        console.error('Error saving settings:', error);

        // Try to save settings to localStorage as fallback
        try {
          localStorage.setItem('model-settings', JSON.stringify(settings));
          messageDiv.textContent = 'Settings saved locally (fallback mode).';
          messageDiv.className = 'status success';

          // Re-enable save button
          saveBtn.disabled = false;
        } catch (storageErr) {
          messageDiv.textContent = 'Could not save settings: ' + error.message;
          messageDiv.className = 'status error';
          saveBtn.disabled = false;
        }
      }
    });

    cancelBtn.addEventListener('click', () => {
      window.close();
    });

    // Initialize
    loadCurrentSettings();

    // Add event listener for the Escape key
    document.addEventListener('keydown', (event) => {
      if (event.key === 'Escape') {
        window.close();
      }
    });

    // Register for keyboard events to handle shortcuts
    document.addEventListener('keydown', (e) => {
      // Allow event to propagate to text fields
      if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA') {
        return;
      }

      // Don't process if some modifier keys are pressed (to avoid conflicts)
      if (e.altKey) return;

      const ctrlOrCmd = isMac ? e.metaKey : e.ctrlKey;

      // If Ctrl/Cmd key is pressed
      if (ctrlOrCmd) {
        switch (e.key) {
          case 'b': // Toggle visibility
            ipcRenderer.send('toggle-visibility');
            e.preventDefault();
            break;
        }
      }
    });

    // Listen for visibility updates from main process
    ipcRenderer.on('update-visibility', (event, isVisible) => {
      document.body.style.opacity = isVisible ? '1' : '0';
    });
  </script>
</body>

</html>